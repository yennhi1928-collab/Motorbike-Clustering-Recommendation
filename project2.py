import streamlit as st
import pandas as pd
import numpy as np
import pickle
import random
import unicodedata
import re
import string
from pyvi.ViTokenizer import tokenize
from underthesea import pos_tag
from nltk.tokenize import sent_tokenize
import joblib
import datetime as dt
import nltk
import os

# -------------------------
# Streamlit app
# -------------------------
st.set_page_config(page_title="Ph√¢n C·ª•m & G·ª£i √ù Xe M√°y", layout="wide")
st.image("xe_may_cu.png", use_container_width=True)

# -------------------------
# Utility functions
# -------------------------
def load_dict(file_path):
    d = {}
    with open(file_path, 'r', encoding='utf8') as f:
        for line in f:
            if '\t' in line:
                key, value = line.strip().split('\t', 1)
                d[key.lower()] = value
    return d

emoji_dict = load_dict('files/emojicon.txt')
teen_dict = load_dict('files/teencode.txt')
english_dict = load_dict('files/english-vnmese.txt')

with open('files/wrong-word.txt', 'r', encoding='utf8') as f:
    wrong_lst = set(line.strip() for line in f if line.strip())

with open('files/vietnamese-stopwords.txt', 'r', encoding='utf8') as f:
    stopwords_lst = set(f.read().splitlines())

# -------------------------
# Text preprocessing
# -------------------------
def process_query(text):
    if not isinstance(text, str):
        text = str(text)
    text = unicodedata.normalize("NFC", text.lower())
    text = text.replace("‚Äô", "'")
    text = re.sub(r'\.+', '.', text)

    # Replace emoji
    text = ' '.join(emoji_dict.get(w, w) for w in text.split())
    # Teencode ‚Üí chu·∫©n
    text = ' '.join(teen_dict.get(w, w) for w in text.split())
    # Remove wrong words
    text = ' '.join([w for w in text.split() if w not in wrong_lst])
    # Cleaning
    text = unicodedata.normalize("NFKC", text)
    text = re.sub(r"<[^>]+>", " ", text)
    text = re.sub(r"http\S+|www\S+|\d{9,11}", " ", text)
    text = re.sub(r"[^a-zA-Z√Ä-·ªπ0-9_\s]", " ", text)
    text = re.sub(r"\b\d+\b", " ", text)
    text = re.sub(r"(.)\1{2,}", r"\1", text)
    text = re.sub(r"\s+", " ", text).strip()
    # English ‚Üí Vietnamese
    text = ' '.join([english_dict.get(w.lower(), w) for w in text.split()])
    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    text = re.sub(r'\s+', ' ', text).strip()
    # Tokenize & POS tagging
    text = tokenize(text)
    tagged = pos_tag(text)
    text = " ".join([w for w, t in tagged if t in ("N", "A", "V", "R")])
    # Remove stopwords
    text = " ".join([w for w in text.split() if w not in stopwords_lst])
    return text

# -------------------------
# Load model & data
# -------------------------
@st.cache_resource
def load_gensim_model():
    with open("xe_gensim_sim.pkl", "rb") as f:
        return pickle.load(f)

@st.cache_resource
def load_cluster_model():
    return joblib.load("cluster_pipeline.pkl")

@st.cache_data
def load_data():
    df = pd.read_excel("data_motobikes.xlsx")
    d = {ord('ƒë'): 'd', ord('ƒê'): 'D'}
    def clean_col(name):
        s = unicodedata.normalize('NFKD', str(name)).translate(d)
        s = ''.join(ch for ch in s if not unicodedata.combining(ch))
        return re.sub(r'\W+', '_', s.lower()).strip('_')
    df.columns = [clean_col(c) for c in df.columns]
    return df

gensim_model = load_gensim_model()
cluster_pipeline = load_cluster_model()
df_data = load_data()

# -------------------------
# Header container
# -------------------------
col_left, col_right = st.columns([5, 1])
with col_left:
    st.markdown("<h1 style='margin:0; color:#ffb400;'>Ph√¢n C·ª•m & G·ª£i √ù Xe M√°y</h1>", unsafe_allow_html=True)
    st.markdown(
    "<p style='margin:5px 0 0 0; font-size:14px; font-weight:bold; color:#000; "
    "text-align:left; white-space:nowrap; font-style:italic;'>"
    "S·∫£n ph·∫©m c·ªßa nh√≥m Xu√¢n Mai & Y·∫øn Nhi, ng√†y 29/11/2025</p>",
    unsafe_allow_html=True
)
with col_right:
    st.image("logo.png", width=150)

# -------------------------
# Tabs
# -------------------------
tabs = st.tabs([
    "üè† Gi·ªõi Thi·ªáu",
    "üìà Ch·ªçn M√¥ H√¨nh",
    "üîç G·ª£i √ù Xe M√°y",
    "üõµ Ph√¢n C·ª•m Xe M√°y"
])

# -------------------------
# TAB 1 ‚Äì HOME
# -------------------------
with tabs[0]:
    st.title("üè† Gi·ªõi Thi·ªáu")
    st.write("H·ªá th·ªëng cung c·∫•p **2 ch·ª©c nƒÉng ch√≠nh d·ª±a tr√™n d·ªØ li·ªáu xe m√°y c≈© t·ª´ Ch·ª£ T·ªët**:")

    col_left, col_right = st.columns([2, 1])

    with col_left:
        st.markdown("""
        <div style="background-color:#ffffff; padding:20px; border-radius:12px; border:1px solid #000; 
                    margin-bottom:15px;">
            <h4 style="color:#ff9800;">üîç G·ª£i √ù Xe M√°y</h4>
            <p>T√¨m nh·ªØng xe m√°y t∆∞∆°ng t·ª± d·ª±a tr√™n m√¥ t·∫£ c·ªßa ng∆∞·ªùi d√πng ho·∫∑c xe m·∫´u b·∫±ng m√¥ h√¨nh Gensim.</p>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("""
        <div style="background-color:#ffffff; padding:20px; border-radius:12px; border:1px solid #000;">
            <h4 style="color:#ff9800;">üõµ Ph√¢n C·ª•m Xe M√°y</h4>
            <p>T·ª± ƒë·ªông ph√¢n lo·∫°i xe m√°y th√†nh 3 c·ª•m d·ª±a tr√™n th∆∞∆°ng hi·ªáu, lo·∫°i xe, dung t√≠ch, nƒÉm s·∫£n xu·∫•t, km ƒë√£ ƒëi, v√† gi√° b√°n.</p>
        </div>
        """, unsafe_allow_html=True)

    with col_right:
        total_bikes = len(df_data)
        total_clusters = len(df_data['cluster'].unique()) if 'cluster' in df_data.columns else 3

        st.markdown(f"""
        <div style="background-color:#ffffff; padding:15px 20px; border-radius:12px; border:1px solid #000; 
                    text-align:left; margin-bottom:15px;">
            <h4 style="color:#ff9800; margin:0 0 5px 0;">T·ªïng s·ªë xe</h4>
            <p style="font-size:24px; font-weight:bold; margin:0;">{total_bikes:,}</p>
        </div>
        """, unsafe_allow_html=True)

        st.markdown(f"""
        <div style="background-color:#ffffff; padding:15px 20px; border-radius:12px; border:1px solid #000; 
                    text-align:left;">
            <h4 style="color:#ff9800;">T·ªïng s·ªë c·ª•m üü¢üîµüü†</h4>
            <p style="font-size:20px; font-weight:bold;">{total_clusters}</p>
            <ul style="margin:5px 0 0 20px; padding:0;">
                <li>üü¢ C·ª•m 0 ‚Äì Xe ph·ªï bi·∫øn gi√° th·∫•p</li>
                <li>üîµ C·ª•m 1 ‚Äì Xe ph·ªï th√¥ng, √≠t km</li>
                <li>üü† C·ª•m 2 ‚Äì Xe m·ªõi cao c·∫•p</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")
    st.markdown("""
    <div style="background-color:#ffffff; color:#000; padding:12px; border-radius:12px; font-size:16px; margin-bottom:15px;">
        üëâ Chuy·ªÉn sang tab ti·∫øp theo ƒë·ªÉ xem qu√° tr√¨nh ch·ªçn m√¥ h√¨nh.
    </div>
    """, unsafe_allow_html=True)

# -------------------------
# TAB 2 ‚Äì MODEL SELECTION
# -------------------------
with tabs[1]:
    st.title("üìà Ch·ªçn M√¥ H√¨nh")
    st.write("T√≥m t·∫Øt c√°c m√¥ h√¨nh G·ª£i √ù v√† Ph√¢n C·ª•m:")
    st.image("Summarize.png", use_container_width=True)
    st.write("S·∫£n ph·∫©m ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi nh√≥m ch√∫ng t√¥i:")
    st.image("team.png", use_container_width=True)

# -------------------------
# TAB 3 ‚Äì RECOMMENDATION
# -------------------------
with tabs[2]:
    st.title("üîç G·ª£i √ù Xe M√°y")
    st.markdown("""
    <div style="background-color:#ffffff; color:#000; padding:15px; border-radius:12px; font-size:16px;">
        üîπ Ch·ªçn m·ªôt xe m·∫´u ho·∫∑c nh·∫≠p m√¥ t·∫£, sau ƒë√≥ nh·∫•n n√∫t ƒë·ªÉ t√¨m c√°c xe t∆∞∆°ng t·ª±.
    </div>
    """, unsafe_allow_html=True)

    df = df_data.copy()
    sample_df = df.sample(10, random_state=42).reset_index(drop=True)
    sample_df_display = sample_df.assign(
        content=sample_df['tieu_de'] + " ‚Äì " + sample_df['mo_ta_chi_tiet']
    )[['id','tieu_de','mo_ta_chi_tiet','content']]

    sample_df_display = sample_df_display.rename(columns={
        "id": "ID",
        "tieu_de": "Ti√™u ƒê·ªÅ",
        "mo_ta_chi_tiet": "M√¥ T·∫£ Chi Ti·∫øt",
        "content": "N·ªôi Dung"
    })

    st.subheader("C√°c Xe M·∫´u")
    st.dataframe(sample_df_display)

    selected_title = st.selectbox("Ch·ªçn m·ªôt xe:", sample_df['tieu_de'].tolist())
    query_text = st.text_area("Ho·∫∑c nh·∫≠p m√¥ t·∫£ xe:")

    if st.button("üîç T√¨m Xe T∆∞∆°ng T·ª±"):
        try:
            if selected_title and not query_text.strip():
                item = df[df["tieu_de"] == selected_title].iloc[0]
                original_text = item["mo_ta_chi_tiet"]
                query = process_query(original_text)
                header_text = f"**Xe ƒë√£ ch·ªçn:** {item['tieu_de']}"
            else:
                original_text = query_text.strip()
                query = process_query(original_text)
                header_text = "**M√¥ t·∫£ nh·∫≠p v√†o:**"

            tokens = query.split()
            query_bow = gensim_model["dictionary"].doc2bow(tokens)
            sims = np.array(gensim_model["index"][gensim_model["tfidf"][query_bow]]).flatten()
            top_idx = sims.argsort()[::-1][1:4]
            top_ids = [gensim_model["id_map"][i] for i in top_idx]
            top3_df = df.set_index('id').loc[top_ids].reset_index()
            top3_df = top3_df.assign(
                content=top3_df['tieu_de'] + " ‚Äì " + top3_df['mo_ta_chi_tiet']
            )[['id', 'tieu_de', 'mo_ta_chi_tiet', 'content']]

            top3_df = top3_df.rename(columns={
                "id": "ID",
                "tieu_de": "Ti√™u ƒê·ªÅ",
                "mo_ta_chi_tiet": "M√¥ T·∫£ Chi Ti·∫øt",
                "content": "N·ªôi Dung"
            })

            st.subheader("üìù Th√¥ng Tin Xe / M√¥ T·∫£")
            st.markdown(
                f"<div style='background-color:#ffffff; padding:15px; border-radius:12px;'>"
                f"<b>{header_text}</b><br>{original_text}</div>",
                unsafe_allow_html=True
            )

            st.subheader("üîé Top 3 Xe T∆∞∆°ng T·ª±")
            st.markdown(
                f"<div style='background-color:#ffffff; padding:15px; border-radius:12px;'>"
                f"{top3_df.to_html(index=False)}</div>",
                unsafe_allow_html=True
            )

        except Exception as e:
            st.error(f"L·ªói: {e}")

# -------------------------
# TAB 4 ‚Äì CLUSTERING
# -------------------------
with tabs[3]:
    st.title("üõµ Ph√¢n C·ª•m Xe M√°y")
    st.markdown("""
    <div style="background-color:#ffffff; color:#000; padding:15px; border-radius:12px; font-size:16px;">
        üîπ Nh·∫≠p th√¥ng tin xe ƒë·ªÉ d·ª± ƒëo√°n c·ª•m thu·ªôc v·ªÅ:
    </div>
    """, unsafe_allow_html=True)

    cluster_info = {
        0: {"icon": "üü¢", "name": "C·ª•m ‚Äì Xe ph·ªï bi·∫øn gi√° th·∫•p", "desc": "Xe c≈©, ch·∫°y nhi·ªÅu km, gi√° th·∫•p, ch·ªß y·∫øu Honda/Yamaha, tay ga/xe s·ªë ph·ªï th√¥ng."},
        1: {"icon": "üîµ", "name": "C·ª•m ‚Äì Xe ph·ªï th√¥ng, √≠t km", "desc": "Xe ph·ªï th√¥ng, √≠t km, gi√° th·∫•p‚Äìtrung b√¨nh, ƒëa d·∫°ng lo·∫°i v√† xu·∫•t x·ª©, ch·ªß y·∫øu Honda/Yamaha."},
        2: {"icon": "üü†", "name": "C·ª•m ‚Äì Xe m·ªõi cao c·∫•p", "desc": "Xe m·ªõi, √≠t km, gi√° cao, ch·ªß y·∫øu tay ga v√† tay c√¥n, th∆∞∆°ng hi·ªáu ph·ªï bi·∫øn nh∆∞ng c√≥ xe cao c·∫•p, xu·∫•t x·ª© ƒëa d·∫°ng."}
    }

    threshold = 10
    popular_brands = df['thuong_hieu'].value_counts()
    popular_brands = popular_brands[popular_brands >= threshold].index.tolist()

    def preprocess_categories(df_input):
        df_input = df_input.copy()
        df_input['thuong_hieu_proc'] = df_input['thuong_hieu'].apply(lambda x: x if x in popular_brands else 'Other Brand')
        df_input['dung_tich_xe_proc'] = df_input['dung_tich_xe'].replace({'Kh√¥ng bi·∫øt r√µ': 'Other','ƒêang c·∫≠p nh·∫≠t': 'Other','Nh·∫≠t B·∫£n':'Other'})
        df_input['xuat_xu_proc'] = df_input['xuat_xu'].replace('B·∫£o h√†nh h√£ng','Updating')
        return df_input

    df_proc = preprocess_categories(df)

    brands = sorted(df_proc['thuong_hieu_proc'].dropna().unique())
    loais = sorted(df_proc['loai_xe'].dropna().unique())
    dt_xes = sorted(df_proc['dung_tich_xe_proc'].dropna().unique())
    xuat_xus = sorted(df_proc['xuat_xu_proc'].dropna().unique())

    col1, col2, col3 = st.columns(3)
    with col1:
        brand = st.selectbox("Th∆∞∆°ng Hi·ªáu", brands)
        loai = st.selectbox("Lo·∫°i Xe", loais)
    with col2:
        year = st.number_input("NƒÉm ƒëƒÉng k√Ω", min_value=1979, max_value=dt.date.today().year, value=2015)
        km = st.number_input("S·ªë km ƒë√£ ƒëi", min_value=0, max_value=1200000, value=30000, step=500)
    with col3:
        dt_xe = st.selectbox("Dung t√≠ch", dt_xes)
        xuat_xu = st.selectbox("Xu·∫•t x·ª©", xuat_xus)
        gia_xe = st.number_input("Gi√° (tri·ªáu VND)", min_value=1, max_value=435, value=20)

    if st.button("üîç D·ª± ƒêo√°n C·ª•m"):
        df_input = pd.DataFrame([{
            "Brand": brand, "Type": loai, "Engine Capacity": dt_xe,
            "Origin": xuat_xu, "Kilometers Travelled": km,
            "Bike Age": dt.date.today().year - year,
            "Price (million VND)": gia_xe
        }])
        try:
            pred = cluster_pipeline.predict(df_input.rename(columns={
                "Brand":"thuong_hieu","Type":"loai_xe","Engine Capacity":"dung_tich_xe",
                "Origin":"xuat_xu","Kilometers Travelled":"so_km_da_di",
                "Bike Age":"tuoi_xe","Price (million VND)":"gia"
            }))[0]

            st.subheader("üìã Th√¥ng Tin Xe Nh·∫≠p V√†o")
            st.markdown("<div style='background-color:#ffffff; padding:15px; border-radius:12px;'>", unsafe_allow_html=True)
            st.table(df_input)
            st.markdown("</div>", unsafe_allow_html=True)

            st.subheader("üîç K·∫øt Qu·∫£ Ph√¢n C·ª•m")
            info = cluster_info[pred]
            st.markdown(
                f"<div style='background-color:#ffffff; padding:20px; border-radius:12px;'>"
                f"<h3 style='color:#ff9800;'>{info['icon']} {info['name']}</h3>"
                f"<p style='font-size:16px;'>{info['desc']}</p></div>",
                unsafe_allow_html=True
            )
        except Exception as e:
            st.error(f"L·ªói d·ª± ƒëo√°n c·ª•m: {e}")
